{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Zc_Y0u1-PJRm"
   },
   "outputs": [],
   "source": [
    "data_path = \"/content/dialog_acts.dat\"\n",
    "def cargar_dataset(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # space split\n",
    "            parts = line.strip().split(' ', 1)\n",
    "            if len(parts) == 2:\n",
    "                dialog_act, utterance_content = parts\n",
    "                data.append((dialog_act, utterance_content))\n",
    "            else:\n",
    "                print(f\"Incorrect line: {line}\")\n",
    "    return data\n",
    "\n",
    "data = cargar_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WmPHihUQPUkC"
   },
   "outputs": [],
   "source": [
    "def baseline_classifier(dataset):\n",
    "    predictions = []\n",
    "    for i in range(len(dataset)):\n",
    "        predictions.append('inform')  # by default\n",
    "    return predictions\n",
    "\n",
    "#  Evaluation\n",
    "def evaluate(predictions, dataset):\n",
    "    correct = 0\n",
    "    total = len(dataset)\n",
    "\n",
    "    for i, (dialog_act, _) in enumerate(dataset):\n",
    "        if predictions[i] == dialog_act:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duc8dBi4PpMd",
    "outputId": "617e7763-8b8f-4e6e-d3e2-289da7cce055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "predictions = baseline_classifier(data)\n",
    "evaluate(predictions,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GFh7ElL1qqq_"
   },
   "outputs": [],
   "source": [
    "def filtrar_dataset(dataset, dialog_acts_filtrar):\n",
    "    dataset_filtrado = []\n",
    "\n",
    "    for dialog_act, utterance_content in dataset:\n",
    "        if dialog_act in dialog_acts_filtrar:\n",
    "            dataset_filtrado.append((dialog_act, utterance_content))\n",
    "\n",
    "    return dataset_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PC86x3Q0oMrx"
   },
   "outputs": [],
   "source": [
    "acts = [\"hello\", \"inform\", \"negate\", \"null\", \"repeat\"]\n",
    "mydata = filtrar_dataset(data,acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "414utXn8rc2Q"
   },
   "outputs": [],
   "source": [
    "# Keywords\n",
    "def rule_based_classifier(dataset):\n",
    "    predictions = []\n",
    "\n",
    "    for _, utterance in dataset:\n",
    "\n",
    "        utterance_lower = utterance.lower()\n",
    "\n",
    "        # Rule 'hello'\n",
    "        if any(keyword in utterance_lower for keyword in ['hi', 'hello', 'halo', 'welcome']):\n",
    "            predictions.append('hello')\n",
    "\n",
    "        # Rule 'inform'\n",
    "        elif any(keyword in utterance_lower for keyword in ['looking', 'restaurant', 'any', 'food', 'part', 'town',\n",
    "                                                           'cheap', 'expensive', 'mediterranean', 'seafood', 'east',\n",
    "                                                           'west', 'north', 'south', 'asian', 'oriental', 'scottish',\n",
    "                                                           'matter', 'european', 'want', 'care', 'austrian', 'center',\n",
    "                                                           'corsica', 'international', 'priced', 'moderately', 'moderate',\n",
    "                                                           'central', 'eirtrean', 'spanish', 'venue', 'australian', 'turkish']):\n",
    "            predictions.append('inform')\n",
    "\n",
    "        # Rule 'negate'\n",
    "        elif 'no' in utterance_lower:\n",
    "            predictions.append('negate')\n",
    "\n",
    "        # Rule 'null'\n",
    "        elif any(keyword in utterance_lower for keyword in ['noise', 'sil', 'cough', 'unintelligible', 'tv_noise',\n",
    "                                                           'hm', 'survey', 'sorry', 'left']):\n",
    "            predictions.append('null')\n",
    "\n",
    "        # Rule 'repeat'\n",
    "        elif any(keyword in utterance_lower for keyword in ['repeat', 'again', 'back']):\n",
    "            predictions.append('repeat')\n",
    "\n",
    "        # by default (inform)\n",
    "        else:\n",
    "            predictions.append('inform')\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HnOgy7R_p90m"
   },
   "outputs": [],
   "source": [
    "pred2 = rule_based_classifier(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMAg5YfmridW",
    "outputId": "b8e32fbc-0df6-4162-b1fe-8c9eaf165bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "evaluate(pred2,mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuqIMHLgrsER"
   },
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "SrhPQ4K_ydvy"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "DUAGGs3Vu5v_"
   },
   "outputs": [],
   "source": [
    "#convert text into Bag of Words representation\n",
    "def preprocess_data(data):\n",
    "    # sentence\n",
    "    utterances = [utterance for _, utterance in data]\n",
    "\n",
    "    # utterances into a Bag of Words representation\n",
    "    vectorizer = CountVectorizer(lowercase=True)  # Remove stop_words\n",
    "    X = vectorizer.fit_transform(utterances)  # Transform sentences into BoW\n",
    "    return X, vectorizer\n",
    "\n",
    "# Train the Decision Tree classifier\n",
    "def train_decision_tree_classifier(X_train, y_train):\n",
    "    # Adjusting hyperparameters to avoid overfitting and improve accuracy\n",
    "    clf_tree = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        max_depth=20,  # Limits the depth of the tree\n",
    "        min_samples_split=5,  # Minimum samples required to split an internal node\n",
    "        criterion='entropy'  # Using entropy as the criterion (information gain)\n",
    "    )\n",
    "    clf_tree.fit(X_train, y_train)\n",
    "    return clf_tree\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Decision Tree model accuracy: {accuracy:.2f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Interactive classification\n",
    "def classify_sentence(model, vectorizer):\n",
    "    while True:\n",
    "        input_sentence = input(\"\\nEnter a sentence (or 'exit' to quit): \")\n",
    "        if input_sentence.lower() == 'exit':\n",
    "            break\n",
    "        input_bow = vectorizer.transform([input_sentence])\n",
    "        prediction = model.predict(input_bow)\n",
    "        print(f\"The predicted dialog act is: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhTtDsGNzNe0",
    "outputId": "225cdc04-cc63-4673-8459-e96764d588c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model accuracy: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ack       0.00      0.00      0.00         5\n",
      "      affirm       0.99      0.94      0.97       180\n",
      "         bye       0.97      0.89      0.93        35\n",
      "     confirm       0.78      0.82      0.80        22\n",
      "        deny       0.00      0.00      0.00         6\n",
      "       hello       1.00      0.43      0.60        14\n",
      "      inform       0.91      0.99      0.95      1532\n",
      "      negate       1.00      1.00      1.00        69\n",
      "        null       0.98      0.72      0.83       232\n",
      "      repeat       0.00      0.00      0.00         3\n",
      "     reqalts       0.97      0.93      0.95       279\n",
      "     reqmore       0.00      0.00      0.00         1\n",
      "     request       0.99      0.97      0.98       972\n",
      "     restart       0.00      0.00      0.00         2\n",
      "    thankyou       1.00      1.00      1.00       474\n",
      "\n",
      "    accuracy                           0.95      3826\n",
      "   macro avg       0.64      0.58      0.60      3826\n",
      "weighted avg       0.95      0.95      0.95      3826\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Extract the labels (dialog acts) from the tuples\n",
    "labels = [dialog_act for dialog_act, _ in data]\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "X, vectorizer = preprocess_data(data)\n",
    "\n",
    "# Split the data into training and testing sets (increased test size for better generalization)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.15, random_state=42)\n",
    "\n",
    "# Step 3: Train the Decision Tree classifier\n",
    "clf_tree = train_decision_tree_classifier(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model's performance\n",
    "evaluate_model(clf_tree, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qL77GHTyDxS",
    "outputId": "01c0aa2a-15f9-4140-c1d2-68e2675ab66a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interactive test with the Decision Tree model:\n",
      "\n",
      "Enter a sentence (or 'exit' to quit): more\n",
      "The predicted dialog act is: inform\n",
      "\n",
      "Enter a sentence (or 'exit' to quit): okay start over\n",
      "The predicted dialog act is: inform\n",
      "\n",
      "Enter a sentence (or 'exit' to quit): chinese\n",
      "The predicted dialog act is: inform\n",
      "\n",
      "Enter a sentence (or 'exit' to quit): cough\n",
      "The predicted dialog act is: inform\n",
      "\n",
      "Enter a sentence (or 'exit' to quit): jyf\n",
      "The predicted dialog act is: inform\n",
      "\n",
      "Enter a sentence (or 'exit' to quit): noise\n",
      "The predicted dialog act is: null\n"
     ]
    }
   ],
   "source": [
    "# Interactive sentence classification\n",
    "print(\"\\nInteractive test with the Decision Tree model:\")\n",
    "classify_sentence(clf_tree, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3BlRIrUIoWA",
    "outputId": "681d60bc-f731-4a6e-d1e2-5b4897f4a624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9522029988465974\n",
      "Test Accuracy: 0.9545216936748563\n"
     ]
    }
   ],
   "source": [
    "# Accuracy - Training set\n",
    "train_predictions = clf_tree.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "# Accuracy - Test set\n",
    "test_predictions = clf_tree.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "1JNa9BPQIowI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
