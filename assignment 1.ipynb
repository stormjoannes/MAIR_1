{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71af04b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\storm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f16444b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"dialog_acts.dat\", 'r') as file:\n",
    "    data = {'label': [], 'sentence': [], 'prediction': []}\n",
    "    \n",
    "    for line in file:\n",
    "        words = line.split(maxsplit=1)\n",
    "        if len(words) > 1:\n",
    "            data['label'].append(words[0])\n",
    "            data['sentence'].append(words[1])\n",
    "        else:\n",
    "            data['label'].append(words[0])\n",
    "            data['sentence'].append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acad049",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in data[\"sentence\"]:\n",
    "    data[\"prediction\"].append(\"inform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ac3de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.84%\n"
     ]
    }
   ],
   "source": [
    "if len(data['label']) != len(data['prediction']):\n",
    "    print(\"Error: The number of labels and predictions do not match.\")\n",
    "else:\n",
    "    correct = 0\n",
    "    total = len(data['label'])\n",
    "\n",
    "    for i in range(total):\n",
    "        if data['label'][i] == data['prediction'][i]:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581933d1-ed55-41d2-ba11-1e71fa958466",
   "metadata": {},
   "source": [
    "# Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4e7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(data):\n",
    "    label_counts = {}\n",
    "\n",
    "    # Count the occurrences of each label\n",
    "    for label in data['label']:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1\n",
    "\n",
    "    # Print the count of each label\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9a0151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inform: 10160\n",
      "confirm: 172\n",
      "affirm: 1156\n",
      "request: 6494\n",
      "thankyou: 3259\n",
      "null: 1612\n",
      "bye: 266\n",
      "reqalts: 1747\n",
      "negate: 435\n",
      "hello: 93\n",
      "repeat: 33\n",
      "ack: 28\n",
      "restart: 14\n",
      "deny: 27\n",
      "reqmore: 5\n"
     ]
    }
   ],
   "source": [
    "count_labels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c78dc45-0ae5-418c-9447-06cae866aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = {\n",
    "#     'ack': ['kay', 'okay'],\n",
    "#     'affirm': ['yes', 'right', 'yeah'],\n",
    "#     'bye': ['bye'],\n",
    "#     'confirm': ['is it', 'does it', 'do they'],\n",
    "#     'deny': ['wrong', 'dont want', 'no']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4577df02-9324-4d9a-bcba-b19d7f79ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    'ack': ['kay', 'okay'],\n",
    "    'affirm': ['yes', 'right', 'yeah'],\n",
    "    'thankyou': ['thank'],\n",
    "    'bye': ['bye', 'goodbye'],\n",
    "    'confirm': ['is it', 'does it', 'do they'],\n",
    "    'deny': ['wrong', 'dont', 'not'],\n",
    "    'hello': ['hi', 'hello', 'halo', 'welcome'],\n",
    "    'inform': [\n",
    "        'looking', 'restaurant', 'any', 'food', 'part', 'town', 'cheap', 'expensive', \n",
    "        'mediterranean', 'seafood', 'east', 'west', 'north', 'south', 'asian', \n",
    "        'oriental', 'scottish', 'matter', 'european', 'want', 'care', 'austrian', \n",
    "        'center', 'corsica', 'international', 'priced', 'moderately', 'moderate', \n",
    "        'central', 'eirtrean', 'spanish', 'venue', 'australian', 'turkish'\n",
    "    ],\n",
    "    'negate': ['no'],\n",
    "    'null': [],\n",
    "    'repeat': ['repeat', 'again', 'back'],\n",
    "    'reqalts': ['how about', 'what about', 'is there', 'anything else'],\n",
    "    'reqmore': ['more'],\n",
    "    'request': ['address', 'phone', 'number', 'post code', 'how much', 'where', 'whats', 'what is', 'price range'],\n",
    "    'restart': ['start', 'reset'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3431966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not 2 word friendly\n",
    "\n",
    "# def classify_sentence(sentence, keywords):\n",
    "#     # Convert the sentence to lowercase and tokenize it\n",
    "#     tokens = re.findall(r'\\b\\w+\\b', sentence.lower())\n",
    "    \n",
    "#     # Check each label and its associated keywords\n",
    "#     for label, kws in keywords.items():\n",
    "#         # Check if any keyword is in the tokens\n",
    "#         if any(keyword in tokens for keyword in kws):\n",
    "#             return label\n",
    "            \n",
    "#     # Return 'null' if no keywords are found\n",
    "#     return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365c3614-b67b-442f-b397-f985834a497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence(sentence, keywords):\n",
    "    # Convert the sentence to lowercase\n",
    "    sentence_lower = sentence.lower()\n",
    "    \n",
    "    # Sort keywords by length in descending order to match longer phrases first\n",
    "    sorted_keywords = sorted(((label, keyword) for label, kw_list in keywords.items() for keyword in kw_list),\n",
    "                              key=lambda x: len(x[1]), reverse=True)\n",
    "    \n",
    "    # Check if any keyword is in the sentence\n",
    "    for label, keyword in sorted_keywords:\n",
    "        if keyword in sentence_lower:\n",
    "            return label\n",
    "    \n",
    "    # Return 'null' if no keywords are found\n",
    "    return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e1515e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['prediction'] = [classify_sentence(sentence, keywords) for sentence in data['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "077c8afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.48307909493745\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy_filtered(labels, predictions):\n",
    "    filtered_labels = []\n",
    "    filtered_predictions = []\n",
    "    \n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        filtered_labels.append(label)\n",
    "        filtered_predictions.append(prediction)\n",
    "    \n",
    "    if len(filtered_labels) != len(filtered_predictions):\n",
    "        raise ValueError(\"Filtered labels and predictions lists must be of the same length.\")\n",
    "    \n",
    "    correct = sum(1 for l, p in zip(filtered_labels, filtered_predictions) if l == p)\n",
    "    total = len(filtered_labels)\n",
    "    accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_accuracy_filtered(data['label'], data['prediction'])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "662b3482-e848-41fe-a7d0-246d94f3a16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: inform, Accuracy: 79.60%\n",
      "Label: confirm, Accuracy: 51.16%\n",
      "Label: affirm, Accuracy: 80.62%\n",
      "Label: request, Accuracy: 88.10%\n",
      "Label: thankyou, Accuracy: 87.11%\n",
      "Label: null, Accuracy: 61.29%\n",
      "Label: bye, Accuracy: 74.44%\n",
      "Label: reqalts, Accuracy: 85.00%\n",
      "Label: negate, Accuracy: 70.11%\n",
      "Label: hello, Accuracy: 49.46%\n",
      "Label: repeat, Accuracy: 100.00%\n",
      "Label: ack, Accuracy: 60.71%\n",
      "Label: restart, Accuracy: 92.86%\n",
      "Label: deny, Accuracy: 81.48%\n",
      "Label: reqmore, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def calculate_accuracy_per_label(labels, predictions):\n",
    "    label_counts = defaultdict(int)  # To count occurrences of each label\n",
    "    correct_counts = defaultdict(int)  # To count correct predictions for each label\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        label_counts[label] += 1\n",
    "        if label == prediction:\n",
    "            correct_counts[label] += 1\n",
    "\n",
    "    accuracy_per_label = {}\n",
    "    for label in label_counts:\n",
    "        total = label_counts[label]\n",
    "        correct = correct_counts[label]\n",
    "        accuracy_per_label[label] = (correct / total) * 100 if total > 0 else 0\n",
    "    \n",
    "    return accuracy_per_label\n",
    "\n",
    "accuracy_per_label = calculate_accuracy_per_label(data['label'], data['prediction'])\n",
    "\n",
    "# Print or inspect the accuracy per label\n",
    "for label, accuracy in accuracy_per_label.items():\n",
    "    print(f\"Label: {label}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f272ab-749a-4da4-88d7-864fad3971c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for label, sentence, prediction in zip(data['label'], data['sentence'], data['prediction']):\n",
    "#     if label == 'confirm':\n",
    "#         print(f\"Sentence: {sentence}, Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429d7738-08be-47a8-95ef-3947c9af47aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence(sentence):\n",
    "    for label, words in keywords.items():\n",
    "        print('words')\n",
    "        if any(word in sentence.lower() for word in words):\n",
    "            return label\n",
    "    return 'Unknown'  # Default label if no keywords are matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36a12eae-1bba-4dca-8c5b-b29d32555677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the classifier.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Get user input\n",
    "    sentence = input(\"Enter a sentence to classify (or type 'exit' to stop): \")\n",
    "    \n",
    "    # Exit condition\n",
    "    if sentence.lower() == 'exit':\n",
    "        print(\"Exiting the classifier.\")\n",
    "        break\n",
    "    \n",
    "    # Classify the sentence\n",
    "    label = classify_sentence(sentence)\n",
    "    print(f\"Classified as: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717aa010-c1cb-43fd-814d-674c39aca6dd",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3745d7a5-4350-46ce-8ca7-c2dda86f5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all labels to numbers\n",
    "le = LabelEncoder()\n",
    "data['label'] = le.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d276ba05-68df-4389-8a89-ad03313625fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000  # Maximum number of words\n",
    "max_len = 128  # Maximum sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fa736ac-01b3-41f2-b89e-f1990048a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all words\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(data['sentence'])\n",
    "sequences = tokenizer.texts_to_sequences(data['sentence'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f8b9803-5917-4794-b5bd-c240051851e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
    "    padded_sequences, data['label'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "309b4136-31d8-48d5-a49e-c4d401862876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Embedding Layer\n",
    "    model.add(layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(15, activation='softmax'))  # 15 classes\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6254e620-ae3a-4253-a129-b58ac4be7cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\storm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 128, 128)          1280000   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4194560   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                3855      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5478415 (20.90 MB)\n",
      "Trainable params: 5478415 (20.90 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c904880a-8b30-465d-b46a-fda817d66920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\storm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\storm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1020/1020 [==============================] - 30s 29ms/step - loss: 0.2824 - accuracy: 0.9228 - val_loss: 0.0925 - val_accuracy: 0.9748\n",
      "Epoch 2/5\n",
      "1020/1020 [==============================] - 30s 29ms/step - loss: 0.0711 - accuracy: 0.9803 - val_loss: 0.0840 - val_accuracy: 0.9757\n",
      "Epoch 3/5\n",
      "1020/1020 [==============================] - 30s 30ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.0781 - val_accuracy: 0.9819\n",
      "Epoch 4/5\n",
      "1020/1020 [==============================] - 30s 29ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.0855 - val_accuracy: 0.9816\n",
      "Epoch 5/5\n",
      "1020/1020 [==============================] - 30s 29ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.1168 - val_accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sentences, train_labels, epochs=5, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18fe83ce-4d19-4c05-852c-91f494f2c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9829\n",
      "Test Accuracy: 98.29%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_sentences, test_labels)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12d6167d-e5a8-44c8-873a-d3bcea074bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = sorted(list(set(data['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "372ed80f-c585-4199-882f-5a7bb8676394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence_fnn(sentence):\n",
    "    # Tokenize and pad the input sentence\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=128, padding='post')\n",
    "    \n",
    "    # Get prediction from the model\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    \n",
    "    # Get the index of the highest probability\n",
    "    predicted_label_index = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_label = le.inverse_transform([predicted_label_index])[0]\n",
    "\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54551130-713e-4c67-9adf-380dc8579a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the classifier.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sentence = input(\"Enter a sentence to classify (or type 'exit' to stop): \")\n",
    "    \n",
    "    if sentence.lower() == 'exit':\n",
    "        print(\"Exiting the classifier.\")\n",
    "        break\n",
    "    \n",
    "    # Classify the sentence using the FNN model\n",
    "    label = classify_sentence_fnn(sentence)\n",
    "    \n",
    "    print(f\"Classified as: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f996309-1f82-47c1-84a2-fbcaa01e4748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
