{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/dialog_acts.dat\"\n",
        "def cargar_dataset(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            # space split\n",
        "            parts = line.strip().split(' ', 1)\n",
        "            if len(parts) == 2:\n",
        "                dialog_act, utterance_content = parts\n",
        "                data.append((dialog_act, utterance_content))\n",
        "            else:\n",
        "                print(f\"Incorrect line: {line}\")\n",
        "    return data\n",
        "\n",
        "data = cargar_dataset(data_path)"
      ],
      "metadata": {
        "id": "Zc_Y0u1-PJRm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_classifier(dataset):\n",
        "    predictions = []\n",
        "    for i in range(len(dataset)):\n",
        "        predictions.append('inform')  # by default\n",
        "    return predictions\n",
        "\n",
        "#  Evaluation\n",
        "def evaluate(predictions, dataset):\n",
        "    correct = 0\n",
        "    total = len(dataset)\n",
        "\n",
        "    for i, (dialog_act, _) in enumerate(dataset):\n",
        "        if predictions[i] == dialog_act:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "WmPHihUQPUkC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = baseline_classifier(data)\n",
        "evaluate(predictions,data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duc8dBi4PpMd",
        "outputId": "73157106-26f3-476c-9799-915e8e7fcfc7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filtrar_dataset(dataset, dialog_acts_filtrar):\n",
        "    dataset_filtrado = []\n",
        "\n",
        "    for dialog_act, utterance_content in dataset:\n",
        "        if dialog_act in dialog_acts_filtrar:\n",
        "            dataset_filtrado.append((dialog_act, utterance_content))\n",
        "\n",
        "    return dataset_filtrado"
      ],
      "metadata": {
        "id": "GFh7ElL1qqq_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acts = [\"hello\", \"inform\", \"negate\", \"null\", \"repeat\"]\n",
        "mydata = filtrar_dataset(data,acts)"
      ],
      "metadata": {
        "id": "PC86x3Q0oMrx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keywords\n",
        "def rule_based_classifier(dataset):\n",
        "    predictions = []\n",
        "\n",
        "    for _, utterance in dataset:\n",
        "\n",
        "        utterance_lower = utterance.lower()\n",
        "\n",
        "        # Rule 'hello'\n",
        "        if any(keyword in utterance_lower for keyword in ['hi', 'hello', 'halo', 'welcome']):\n",
        "            predictions.append('hello')\n",
        "\n",
        "        # Rule 'inform'\n",
        "        elif any(keyword in utterance_lower for keyword in ['looking', 'restaurant', 'any', 'food', 'part', 'town',\n",
        "                                                           'cheap', 'expensive', 'mediterranean', 'seafood', 'east',\n",
        "                                                           'west', 'north', 'south', 'asian', 'oriental', 'scottish',\n",
        "                                                           'matter', 'european', 'want', 'care', 'austrian', 'center',\n",
        "                                                           'corsica', 'international', 'priced', 'moderately', 'moderate',\n",
        "                                                           'central', 'eirtrean', 'spanish', 'venue', 'australian', 'turkish']):\n",
        "            predictions.append('inform')\n",
        "\n",
        "        # Rule 'negate'\n",
        "        elif 'no' in utterance_lower:\n",
        "            predictions.append('negate')\n",
        "\n",
        "        # Rule 'null'\n",
        "        elif any(keyword in utterance_lower for keyword in ['noise', 'sil', 'cough', 'unintelligible', 'tv_noise',\n",
        "                                                           'hm', 'survey', 'sorry', 'left']):\n",
        "            predictions.append('null')\n",
        "\n",
        "        # Rule 'repeat'\n",
        "        elif any(keyword in utterance_lower for keyword in ['repeat', 'again', 'back']):\n",
        "            predictions.append('repeat')\n",
        "\n",
        "        # by default (inform)\n",
        "        else:\n",
        "            predictions.append('inform')\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "414utXn8rc2Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred2 = rule_based_classifier(mydata)"
      ],
      "metadata": {
        "id": "HnOgy7R_p90m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(pred2,mydata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMAg5YfmridW",
        "outputId": "c6ad405f-8f57-43db-e760-601e7e1f82ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Model"
      ],
      "metadata": {
        "id": "QuqIMHLgrsER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "SrhPQ4K_ydvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert text into Bag of Words representation\n",
        "def preprocess_data(data):\n",
        "    # sentence\n",
        "    utterances = [utterance for _, utterance in data]\n",
        "\n",
        "    # utterances into a Bag of Words representation\n",
        "    vectorizer = CountVectorizer(lowercase=True)  # Remove stop_words\n",
        "    X = vectorizer.fit_transform(utterances)  # Transform sentences into BoW\n",
        "    return X, vectorizer\n",
        "\n",
        "# Train the Decision Tree classifier\n",
        "def train_decision_tree_classifier(X_train, y_train):\n",
        "    # Adjusting hyperparameters to avoid overfitting and improve accuracy\n",
        "    clf_tree = DecisionTreeClassifier(\n",
        "        random_state=42,\n",
        "        max_depth=20,  # Limits the depth of the tree\n",
        "        min_samples_split=5,  # Minimum samples required to split an internal node\n",
        "        criterion='entropy'  # Using entropy as the criterion (information gain)\n",
        "    )\n",
        "    clf_tree.fit(X_train, y_train)\n",
        "    return clf_tree\n",
        "\n",
        "# Evaluate the classifier's performance\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Decision Tree model accuracy: {accuracy:.2f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Interactive classification\n",
        "def classify_sentence(model, vectorizer):\n",
        "    while True:\n",
        "        input_sentence = input(\"\\nEnter a sentence (or 'exit' to quit): \")\n",
        "        if input_sentence.lower() == 'exit':\n",
        "            break\n",
        "        input_bow = vectorizer.transform([input_sentence])\n",
        "        prediction = model.predict(input_bow)\n",
        "        print(f\"The predicted dialog act is: {prediction[0]}\")\n"
      ],
      "metadata": {
        "id": "DUAGGs3Vu5v_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the labels (dialog acts) from the tuples\n",
        "labels = [dialog_act for dialog_act, _ in data]\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "X, vectorizer = preprocess_data(data)\n",
        "\n",
        "# Split the data into training and testing sets (increased test size for better generalization)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.15, random_state=42)\n",
        "\n",
        "# Step 3: Train the Decision Tree classifier\n",
        "clf_tree = train_decision_tree_classifier(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the model's performance\n",
        "evaluate_model(clf_tree, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhTtDsGNzNe0",
        "outputId": "b3d2eccd-bac6-4637-9a0b-6e6a76408f25"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree model accuracy: 0.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ack       0.00      0.00      0.00         5\n",
            "      affirm       0.99      0.94      0.97       180\n",
            "         bye       0.97      0.89      0.93        35\n",
            "     confirm       0.78      0.82      0.80        22\n",
            "        deny       0.00      0.00      0.00         6\n",
            "       hello       1.00      0.43      0.60        14\n",
            "      inform       0.91      0.99      0.95      1532\n",
            "      negate       1.00      1.00      1.00        69\n",
            "        null       0.98      0.72      0.83       232\n",
            "      repeat       0.00      0.00      0.00         3\n",
            "     reqalts       0.97      0.93      0.95       279\n",
            "     reqmore       0.00      0.00      0.00         1\n",
            "     request       0.99      0.97      0.98       972\n",
            "     restart       0.00      0.00      0.00         2\n",
            "    thankyou       1.00      1.00      1.00       474\n",
            "\n",
            "    accuracy                           0.95      3826\n",
            "   macro avg       0.64      0.58      0.60      3826\n",
            "weighted avg       0.95      0.95      0.95      3826\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive sentence classification\n",
        "print(\"\\nInteractive test with the Decision Tree model:\")\n",
        "classify_sentence(clf_tree, vectorizer)"
      ],
      "metadata": {
        "id": "2qL77GHTyDxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}