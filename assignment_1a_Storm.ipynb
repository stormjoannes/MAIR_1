{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71af04b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\storm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f16444b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"dialog_acts.dat\", 'r') as file:\n",
    "    data = {'label': [], 'sentence': [], 'prediction': []}\n",
    "    \n",
    "    for line in file:\n",
    "        words = line.split(maxsplit=1)\n",
    "        if len(words) > 1:\n",
    "            data['label'].append(words[0])\n",
    "            data['sentence'].append(words[1])\n",
    "        else:\n",
    "            data['label'].append(words[0])\n",
    "            data['sentence'].append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acad049",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in data[\"sentence\"]:\n",
    "    data[\"prediction\"].append(\"inform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ac3de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.84%\n"
     ]
    }
   ],
   "source": [
    "if len(data['label']) != len(data['prediction']):\n",
    "    print(\"Error: The number of labels and predictions do not match.\")\n",
    "else:\n",
    "    correct = 0\n",
    "    total = len(data['label'])\n",
    "\n",
    "    for i in range(total):\n",
    "        if data['label'][i] == data['prediction'][i]:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4e7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(data):\n",
    "    label_counts = {}\n",
    "\n",
    "    # Count the occurrences of each label\n",
    "    for label in data['label']:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1\n",
    "\n",
    "    # Print the count of each label\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9a0151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inform: 10160\n",
      "confirm: 172\n",
      "affirm: 1156\n",
      "request: 6494\n",
      "thankyou: 3259\n",
      "null: 1612\n",
      "bye: 266\n",
      "reqalts: 1747\n",
      "negate: 435\n",
      "hello: 93\n",
      "repeat: 33\n",
      "ack: 28\n",
      "restart: 14\n",
      "deny: 27\n",
      "reqmore: 5\n"
     ]
    }
   ],
   "source": [
    "count_labels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c78dc45-0ae5-418c-9447-06cae866aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    'ack': ['kay', 'okay'],\n",
    "    'affirm': ['yes', 'right', 'yeah'],\n",
    "    'bye': ['bye'],\n",
    "    'confirm': ['is it', 'does it', 'do they'],\n",
    "    'deny': ['wrong', 'dont want', 'no']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3431966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence(sentence, keywords):\n",
    "    for label, words in keywords.items():\n",
    "        if any(word in sentence.lower() for word in words):\n",
    "            return label\n",
    "    return 'Unknown'  # or some default label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e1515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prediction'] = [classify_sentence(sentence, keywords) for sentence in data['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "077c8afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.59915100060643\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy_filtered(labels, predictions, valid_labels):\n",
    "    filtered_labels = []\n",
    "    filtered_predictions = []\n",
    "    \n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label in valid_labels:\n",
    "            filtered_labels.append(label)\n",
    "            filtered_predictions.append(prediction)\n",
    "    \n",
    "    if len(filtered_labels) != len(filtered_predictions):\n",
    "        raise ValueError(\"Filtered labels and predictions lists must be of the same length.\")\n",
    "    \n",
    "    correct = sum(1 for l, p in zip(filtered_labels, filtered_predictions) if l == p)\n",
    "    total = len(filtered_labels)\n",
    "    accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "valid_labels = {'ack', 'affirm', 'bye', 'confirm', 'deny'}\n",
    "accuracy = calculate_accuracy_filtered(data['label'], data['prediction'], valid_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "429d7738-08be-47a8-95ef-3947c9af47aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence(sentence):\n",
    "    for label, words in keywords.items():\n",
    "        if any(word in sentence.lower() for word in words):\n",
    "            return label\n",
    "    return 'Unknown'  # Default label if no keywords are matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a12eae-1bba-4dca-8c5b-b29d32555677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the classifier.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Get user input\n",
    "    sentence = input(\"Enter a sentence to classify (or type 'exit' to stop): \")\n",
    "    \n",
    "    # Exit condition\n",
    "    if sentence.lower() == 'exit':\n",
    "        print(\"Exiting the classifier.\")\n",
    "        break\n",
    "    \n",
    "    # Classify the sentence\n",
    "    label = classify_sentence(sentence)\n",
    "    print(f\"Classified as: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717aa010-c1cb-43fd-814d-674c39aca6dd",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3745d7a5-4350-46ce-8ca7-c2dda86f5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all labels to numbers\n",
    "le = LabelEncoder()\n",
    "data['label'] = le.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d276ba05-68df-4389-8a89-ad03313625fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000  # Maximum number of words\n",
    "max_len = 128  # Maximum sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa736ac-01b3-41f2-b89e-f1990048a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all words\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(data['sentence'])\n",
    "sequences = tokenizer.texts_to_sequences(data['sentence'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f8b9803-5917-4794-b5bd-c240051851e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
    "    padded_sequences, data['label'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "309b4136-31d8-48d5-a49e-c4d401862876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Embedding Layer\n",
    "    model.add(layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(15, activation='softmax'))  # 15 classes\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6254e620-ae3a-4253-a129-b58ac4be7cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\storm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 128, 128)          1280000   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4194560   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                3855      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5478415 (20.90 MB)\n",
      "Trainable params: 5478415 (20.90 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c904880a-8b30-465d-b46a-fda817d66920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\storm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\storm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1020/1020 [==============================] - 32s 30ms/step - loss: 0.2882 - accuracy: 0.9193 - val_loss: 0.1063 - val_accuracy: 0.9708\n",
      "Epoch 2/5\n",
      "1020/1020 [==============================] - 31s 30ms/step - loss: 0.0706 - accuracy: 0.9798 - val_loss: 0.0938 - val_accuracy: 0.9730\n",
      "Epoch 3/5\n",
      "1020/1020 [==============================] - 30s 30ms/step - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.0770 - val_accuracy: 0.9782\n",
      "Epoch 4/5\n",
      "1020/1020 [==============================] - 31s 30ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 0.0810 - val_accuracy: 0.9799\n",
      "Epoch 5/5\n",
      "1020/1020 [==============================] - 30s 30ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0851 - val_accuracy: 0.9809\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sentences, train_labels, epochs=5, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18fe83ce-4d19-4c05-852c-91f494f2c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9861\n",
      "Test Accuracy: 98.61%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_sentences, test_labels)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12d6167d-e5a8-44c8-873a-d3bcea074bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = sorted(list(set(data['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "372ed80f-c585-4199-882f-5a7bb8676394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence_fnn(sentence):\n",
    "    # Tokenize and pad the input sentence\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=128, padding='post')\n",
    "    \n",
    "    # Get prediction from the model\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    \n",
    "    # Get the index of the highest probability\n",
    "    predicted_label_index = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_label = le.inverse_transform([predicted_label_index])[0]\n",
    "\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2ad2df4-2ddf-437c-9232-61be6bd97be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54551130-713e-4c67-9adf-380dc8579a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  where is my suit?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "12\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Classified as: request\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "7\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Classified as: negate\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  okay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "8\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Classified as: null\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  kay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Classified as: ack\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  goodbye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Classified as: bye\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  thankyou\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "8\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Classified as: null\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Classified as: affirm\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to classify (or type 'exit' to stop):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the classifier.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sentence = input(\"Enter a sentence to classify (or type 'exit' to stop): \")\n",
    "    \n",
    "    if sentence.lower() == 'exit':\n",
    "        print(\"Exiting the classifier.\")\n",
    "        break\n",
    "    \n",
    "    # Classify the sentence using the FNN model\n",
    "    label = classify_sentence_fnn(sentence)\n",
    "    \n",
    "    print(f\"Classified as: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f996309-1f82-47c1-84a2-fbcaa01e4748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
